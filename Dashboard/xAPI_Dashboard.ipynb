{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7601e1d-174d-4df5-99c9-e668401fdb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install dash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "365d3f00-4ada-494a-b2e7-0925603a334c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install dash_bootstrap_components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d70a479-4aa5-461e-8a4d-b72f3fc3d7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install dash_bootstrap_templates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47edad41-511d-48dd-9b41-58ac81bd0b2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1e50df0-36a9-437c-a402-c02810f51c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install dash-auth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd78b15b-3f7d-4ad7-9bd3-f41515ab5f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef8a9c80-3892-40c1-a424-329c69d386c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "103beb49-299d-4250-9434-032200a681bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install mlxtend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54acb94a-a5fc-4dc6-9f86-3895703f7a23",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install prefixspan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4fe697-a09e-4810-8ed3-47a7370509a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install lifelines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406c28ce-e937-4930-b6ab-e3ce3d16fa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip3 install pm4py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ca35564-fdaf-45ac-bb96-e99d431e2472",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "import dash_bootstrap_components as dbc\n",
    "import dash_auth\n",
    "import dash_table\n",
    "from dash import Input, Output, dcc, html\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.cluster import KMeans\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram, cut_tree\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import xgboost as xgb\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "import shap\n",
    "from mlxtend.preprocessing import TransactionEncoder\n",
    "from mlxtend.frequent_patterns import apriori\n",
    "from mlxtend.frequent_patterns import association_rules\n",
    "from collections import defaultdict\n",
    "from collections import Counter\n",
    "from prefixspan import PrefixSpan\n",
    "from lifelines import KaplanMeierFitter\n",
    "import pm4py\n",
    "from pm4py.algo.discovery.heuristics import algorithm as heuristics_miner\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "from pm4py.visualization.heuristics_net import visualizer as hn_visualizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08320d2f-3296-4ae8-90fa-41ed5997246c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv('xapi_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2c6adf-49e3-4424-af0a-69caaed4d39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timestamp'] = pd.to_datetime(df['timestamp'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b99ef797-4d2c-4935-ae84-2d18732c44f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting Date\n",
    "df['date'] = df['timestamp'].dt.date\n",
    "\n",
    "# Extracting Time\n",
    "df['time'] = df['timestamp'].dt.time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "983a7360-e0b3-45ff-9929-3d47c968eb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timeframe(t):\n",
    "    if 0 <= t.hour < 8:\n",
    "        return \"00:00-08:00\"\n",
    "    elif 8 <= t.hour < 16:\n",
    "        return \"08:00-16:00\"\n",
    "    else:\n",
    "        return \"16:00-24:00\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b655ea-6ff8-465e-87dd-1d1009635cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['timeframe'] = df['time'].apply(get_timeframe)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4535852a-d9bf-4596-8fd6-6b9d16335938",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50be3be-7353-496c-9e21-45a635beb804",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataframe for clustering\n",
    "\n",
    "# Sort the data by actor_mbox and timestamp\n",
    "sorted_data_cl = df.sort_values(by=['actor_mbox', 'timestamp'])\n",
    "\n",
    "# Calculate the time difference between consecutive rows\n",
    "sorted_data_cl['time_diff'] = sorted_data_cl.groupby('actor_mbox')['timestamp'].diff()\n",
    "\n",
    "# Set time differences greater than 30 minutes to NaT (Not a Time)\n",
    "threshold = pd.Timedelta(minutes=30)\n",
    "sorted_data_cl.loc[sorted_data_cl['time_diff'] > threshold, 'time_diff'] = pd.NaT\n",
    "\n",
    "# Activity Count\n",
    "activity_count_cl = df.groupby('actor_mbox').size().reset_index(name='activity_count')\n",
    "\n",
    "# Verb Types\n",
    "verb_types_cl = df.groupby(['actor_mbox', 'verb_display_en']).size().reset_index(name='verb_count')\n",
    "verb_types_cl = verb_types_cl.pivot(index='actor_mbox', columns='verb_display_en', values='verb_count').reset_index().fillna(0)\n",
    "\n",
    "# Time Spent\n",
    "def compute_total_time(group):\n",
    "    return group['time_diff'].sum(skipna=True)\n",
    "\n",
    "time_spent_cl = sorted_data_cl.groupby('actor_mbox').apply(compute_total_time).reset_index()\n",
    "time_spent_cl.columns = ['actor_mbox', 'total_time_spent']\n",
    "\n",
    "# Diversity of Interactions\n",
    "diversity_of_interactions_cl = df.groupby('actor_mbox')['obj_id'].nunique().reset_index()\n",
    "diversity_of_interactions_cl.columns = ['actor_mbox', 'unique_materials_count']\n",
    "\n",
    "# Merging all the dataframes together for a complete view\n",
    "cl_df = activity_count_cl.merge(verb_types_cl, on='actor_mbox', how='outer')\n",
    "cl_df = cl_df.merge(time_spent_cl, on='actor_mbox', how='outer')\n",
    "cl_df = cl_df.merge(diversity_of_interactions_cl, on='actor_mbox', how='outer')\n",
    "cl_df['total_time_spent'] = cl_df['total_time_spent'].dt.total_seconds()/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c929ce7-6590-4f4b-ad76-f9251bb23e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "cl_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fced1010-8eaf-4362-bec5-e6662068614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "basic_metrics_cl_df = ['activity_count', 'total_time_spent', 'unique_materials_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d3d6513-e093-4a02-98ec-626b7d19d0cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Update the boxplot graph with further improvements\n",
    "fig_boxplot_basic = go.Figure()\n",
    "\n",
    "# Add boxplots for each variable\n",
    "for var in basic_metrics_cl_df:\n",
    "    fig_boxplot_basic.add_trace(go.Box(\n",
    "        y=cl_df[var], \n",
    "        name=var,\n",
    "        boxpoints='all',  # Display all points\n",
    "        jitter=0.4,  # Spread them out so they don't overlap\n",
    "        pointpos=-1.8,  # Position points to the side of the boxplot\n",
    "        marker=dict(size=4, opacity=0.6),  # Slightly larger points with some transparency\n",
    "        line=dict(width=1)\n",
    "    ))\n",
    "\n",
    "fig_boxplot_basic.update_layout(\n",
    "    title_text=\"Boxplots for Key Engagement Variables\",  # Title\n",
    "    title_font_size=20,\n",
    "    title_x=0.5,  # Center the title\n",
    "    xaxis=dict(\n",
    "        title='Variables',  # X-axis label\n",
    "        titlefont_size=16,\n",
    "        tickangle=45,  # Rotate labels for better readability\n",
    "        tickfont_size=12,\n",
    "        automargin=True,  # Ensure there's enough margin for the tick labels\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Values',  # Y-axis label\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=12,\n",
    "        autorange=True,  # Automatically adjust the range of the y-axis\n",
    "    ),\n",
    "    hovermode=\"closest\",  # Show tooltip for the closest point\n",
    "    showlegend=False,  # Hide legend if not necessary\n",
    "    plot_bgcolor='white',  # Set background to white for a clean look\n",
    "    boxmode='group'  # Group boxplots when they have the same x coordinate\n",
    ")\n",
    "\n",
    "# Add hovertemplate for more detailed information on hover\n",
    "for trace in fig_boxplot_basic.data:\n",
    "    trace.hovertemplate = '%{y}<extra>%{name}</extra>'\n",
    "\n",
    "# Show the figure\n",
    "fig_boxplot_basic.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da815c8-f3bc-4ec3-b549-920c7b2a4ddb",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_text_clustering = \"\"\"\n",
    "In our clustering analysis of xAPI statement data, we employed three distinct techniques: DBSCAN, K-means, and Hierarchical Clustering. Each method segmented learners based on three key metrics: the count of activities undertaken, the total time spent on materials, and the count of unique materials interacted with. DBSCAN helped us identify outliers and the core groups of learners with similar activity patterns, highlighting those who deviated significantly from the norm. K-means clustering partitioned the learners into distinct groups, optimizing for intra-cluster similarity and inter-cluster differences, revealing common engagement profiles among learners. Hierarchical clustering provided a dendrogram that depicted the relationships between learners, allowing us to visualize the data's natural structure and determine a hierarchy of learner groups. This multi-faceted clustering approach not only categorized learners based on their engagement levels but also offered insights into the diversity of their learning interactions, and the depth of their engagement, thereby informing targeted interventions for enhanced educational outcomes.\n",
    "\"\"\"\n",
    "info_text_shap=\"\"\"\n",
    "In our analysis, SHAP values provided an in-depth look at the impact of each feature on the clustering outcomes derived from the xAPI data. By applying SHAP to the K-means and Hierarchical clustering models, we could quantify the influence of 'activity count', 'total time spent', and 'unique materials count' on the learners' assignment to different clusters. To visualize this impact, we created custom beeswarm plots using Plotly, where each point represents a SHAP value for a feature across all instances. Larger SHAP values indicate a greater influence on the model's output. These plots were constructed as box plots with all data points displayed, providing a clear, interactive visualization of the distribution of SHAP values for each feature. The boxplot’s spread and skewness gave insights into the consistency of each feature's impact across different learners. With this approach, we could discern which features strongly guided the clustering process, thus offering an interpretable overview of the model's decision-making process. These visualizations, embedded in our Dash application, allowed for an interactive exploration of the model's explanations, making the results accessible and understandable to stakeholders.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f53ec1b-6a1c-4831-80d7-93f4800a705c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Columns to normalize\n",
    "# all the columns ['activity_count', 'total_time_spent', 'unique_materials_count'] + list(df['verb_display_en'].unique())\n",
    "cols_to_normalize = ['activity_count', 'total_time_spent', 'unique_materials_count']\n",
    "cols_to_normalize = [col for col in cols_to_normalize if col == col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7a70021-ad33-4dac-bfe8-70c35b636461",
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bc5575d-da37-4fe5-af17-729ddd838ca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for NaN values in the final_df dataframe\n",
    "nan_counts = cl_df[cols_to_normalize].isna().sum()\n",
    "\n",
    "# Display columns with NaN values and their counts\n",
    "nan_columns = nan_counts[nan_counts > 0]\n",
    "nan_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94258a2f-6140-40fb-91f0-77b3104124ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbs_list=list(df['verb_display_en'].unique())\n",
    "verbs_list = [col for col in verbs_list if col == col]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "782b6d88-9e11-42a8-a1d8-872aaf09a298",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(verbs_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18a9a8d6-6b06-4055-b55d-1180dbdbbeeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure\n",
    "fig_boxplot_verbs = go.Figure()\n",
    "\n",
    "# Add boxplots for each variable\n",
    "for verb in verbs_list:\n",
    "    fig_boxplot_verbs.add_trace(go.Box(y=cl_df[verb], name=verb))\n",
    "\n",
    "# Update the boxplot graph with improvements for readability and information\n",
    "fig_boxplot_verbs.update_traces(\n",
    "    marker=dict(outliercolor='rgba(219, 64, 82, 0.6)', line=dict(outliercolor='rgba(219, 64, 82, 0.6)', outlierwidth=2)),\n",
    "    boxmean=True,  # Represent the mean of the data\n",
    "    boxpoints='outliers'  # show only outliers\n",
    ")\n",
    "\n",
    "fig_boxplot_verbs.update_layout(\n",
    "    title_text=\"Distribution of Verb Interactions\",  # Title\n",
    "    title_font_size=20,\n",
    "    title_x=0.5,  # Center the title\n",
    "    xaxis=dict(\n",
    "        title='Verb Types',  # X-axis label\n",
    "        titlefont_size=16,\n",
    "        tickangle=45,  # Rotate labels for better readability\n",
    "        tickfont_size=12,\n",
    "    ),\n",
    "    yaxis=dict(\n",
    "        title='Frequency',  # Y-axis label\n",
    "        titlefont_size=16,\n",
    "        tickfont_size=12,\n",
    "    ),\n",
    "    hovermode=\"closest\",  # Show tooltip for the closest point\n",
    "    showlegend=False,  # Hide legend if not necessary\n",
    "    plot_bgcolor='white',  # Set background to white for a clean look\n",
    ")\n",
    "\n",
    "# Add hovertemplate for more detailed information on hover\n",
    "for trace in fig_boxplot_verbs.data:\n",
    "    trace.hovertemplate = '%{y} %{x}<extra></extra>'\n",
    "\n",
    "fig_boxplot_verbs.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0978c5c-d98e-4284-9076-ccf3d5f963fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Min-Max Scaler or the StandardScaler (mean=0 and variance=1)\n",
    "scaler = MinMaxScaler()\n",
    "# Apply Min-Max scaling\n",
    "cl_df[cols_to_normalize] = scaler.fit_transform(cl_df[cols_to_normalize])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c87c68-aa90-4459-a8ab-222efff82e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DBSCAN instance\n",
    "dbscan = DBSCAN(eps=0.5, min_samples=5)  # eps and min_samples are key parameters\n",
    "\n",
    "# Fit the data\n",
    "clusters = dbscan.fit_predict(cl_df[cols_to_normalize])\n",
    "\n",
    "cl_df['dbscan_cluster'] = clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57b4447-85b2-40bd-8eac-f0a2d7888a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting numerical columns for PCA\n",
    "data_for_pca = cl_df[cols_to_normalize].fillna(0)\n",
    "\n",
    "# Apply PCA and reduce dimensions to 3\n",
    "pca = PCA(n_components=2)\n",
    "principal_components_cl = pca.fit_transform(data_for_pca)\n",
    "\n",
    "# Convert the principal components to a DataFrame\n",
    "pc_cl_df = pd.DataFrame(data=principal_components_cl, columns=['PC1', 'PC2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5370ec39-4e53-4504-94fd-2072c7d55789",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add cluster labels to the pc_df\n",
    "pc_cl_df['dbscan_cluster'] = cl_df['dbscan_cluster']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91bcf4b7-bfd2-4925-ad3e-a3a80c25a7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Visualization using Plotly's graph_objects\n",
    "# Initialize lists to store circle properties\n",
    "circle_centers = []\n",
    "circle_radii = []\n",
    "\n",
    "# Calculate centroid and furthest distance for each cluster\n",
    "for cluster_num in pc_cl_df['dbscan_cluster'].unique():\n",
    "    cluster_data = pc_cl_df[pc_cl_df['dbscan_cluster'] == cluster_num]\n",
    "    \n",
    "    # Calculate the centroid of the cluster\n",
    "    centroid = [cluster_data['PC1'].mean(), cluster_data['PC2'].mean()]\n",
    "    circle_centers.append(centroid)\n",
    "    \n",
    "    # Calculate the radius as the maximum distance from the centroid\n",
    "    radii = cluster_data.apply(lambda row: distance.euclidean(centroid, [row['PC1'], row['PC2']]), axis=1)\n",
    "    circle_radii.append(radii.max())\n",
    "\n",
    "# Plot the clusters and circles\n",
    "fig_dbscan = go.Figure()\n",
    "\n",
    "# Add scatter plot for each cluster\n",
    "for cluster_num in pc_cl_df['dbscan_cluster'].unique():\n",
    "    cluster_data = pc_cl_df[pc_cl_df['dbscan_cluster'] == cluster_num]\n",
    "    fig_dbscan.add_trace(go.Scatter(x=cluster_data['PC1'], y=cluster_data['PC2'],\n",
    "                                                 mode='markers', name=f'Cluster {cluster_num}'))\n",
    "\n",
    "# Add circle shapes for each cluster\n",
    "for center, radius in zip(circle_centers, circle_radii):\n",
    "    fig_dbscan.add_shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        x0=center[0] - radius, y0=center[1] - radius,\n",
    "        x1=center[0] + radius, y1=center[1] + radius,\n",
    "        opacity=0.2,\n",
    "        fillcolor=\"blue\",\n",
    "        line_color=\"blue\",\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "fig_dbscan.update_layout(title=\"DBSCAN Clusters Visualization\",\n",
    "                                      xaxis_title=\"Principal Component 1\",\n",
    "                                      yaxis_title=\"Principal Component 2\")\n",
    "\n",
    "fig_dbscan.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c9ba55b-02e2-436d-9fff-50fb191bbb13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine the optimal number of clusters using the Elbow Method\n",
    "inertia = []\n",
    "possible_clusters = range(1, 15)  # Checking for up to 14 clusters\n",
    "\n",
    "for k in possible_clusters:\n",
    "    kmeans = KMeans(n_clusters=k, n_init=10, random_state=42).fit(data_for_pca)\n",
    "    inertia.append(kmeans.inertia_)\n",
    "\n",
    "# Plotting the Elbow Method\n",
    "elbow_fig = px.line(x=possible_clusters, y=inertia, title='Elbow Method for Optimal Number of Clusters', \n",
    "                    labels={'x': 'Number of Clusters', 'y': 'Inertia'})\n",
    "elbow_fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee234a0b-c646-422b-8786-6b666a4d1b58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming an arbitrary number of clusters for demonstration\n",
    "k = 2  # This can be changed based on the Elbow Method result\n",
    "\n",
    "# Apply K-means clustering\n",
    "kmeans = KMeans(n_clusters=k, n_init=10, random_state=42)\n",
    "clusters_kmeans = kmeans.fit_predict(data_for_pca)\n",
    "\n",
    "# Add K-means cluster labels to the pc_df\n",
    "pc_cl_df['kmeans_cluster'] = clusters_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafbb721-d203-4d72-a241-3da32d4d8ce4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Visualization using Plotly's graph_objects\n",
    "# Initialize lists to store circle properties for K-means clusters\n",
    "circle_centers_kmeans = []\n",
    "circle_radii_kmeans = []\n",
    "\n",
    "# Calculate centroid and furthest distance for each K-means cluster\n",
    "for cluster_num in pc_cl_df['kmeans_cluster'].unique():\n",
    "    cluster_data = pc_cl_df[pc_cl_df['kmeans_cluster'] == cluster_num]\n",
    "    \n",
    "    # Calculate the centroid of the cluster\n",
    "    centroid = [cluster_data['PC1'].mean(), cluster_data['PC2'].mean()]\n",
    "    circle_centers_kmeans.append(centroid)\n",
    "    \n",
    "    # Calculate the radius as the maximum distance from the centroid\n",
    "    radii = cluster_data.apply(lambda row: distance.euclidean(centroid, [row['PC1'], row['PC2']]), axis=1)\n",
    "    circle_radii_kmeans.append(radii.max())\n",
    "\n",
    "# Plot the K-means clusters and circles\n",
    "fig_kmeans = go.Figure()\n",
    "\n",
    "# Add scatter plot for each cluster\n",
    "for cluster_num in pc_cl_df['kmeans_cluster'].unique():\n",
    "    cluster_data = pc_cl_df[pc_cl_df['kmeans_cluster'] == cluster_num]\n",
    "    fig_kmeans.add_trace(go.Scatter(x=cluster_data['PC1'], y=cluster_data['PC2'],\n",
    "                                                 mode='markers', name=f'Cluster {cluster_num}'))\n",
    "\n",
    "# Add circle shapes for each cluster\n",
    "for center, radius in zip(circle_centers_kmeans, circle_radii_kmeans):\n",
    "    fig_kmeans.add_shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        x0=center[0] - radius, y0=center[1] - radius,\n",
    "        x1=center[0] + radius, y1=center[1] + radius,\n",
    "        opacity=0.2,\n",
    "        fillcolor=\"blue\",\n",
    "        line_color=\"blue\",\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "fig_kmeans.update_layout(title=\"K-means Clusters Visualization\",\n",
    "                                      xaxis_title=\"Principal Component 1\",\n",
    "                                      yaxis_title=\"Principal Component 2\")\n",
    "\n",
    "fig_kmeans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bff71f-78df-404d-9c0d-05b35a3fcd52",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining K-Means\n",
    "# Prepare data and labels for K-means clusters\n",
    "X = data_for_pca\n",
    "y_kmeans = pc_cl_df['kmeans_cluster']\n",
    "\n",
    "# Split data into train and test sets for K-means clusters\n",
    "X_train_kmeans, X_test_kmeans, y_train_kmeans, y_test_kmeans = train_test_split(X, y_kmeans, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model for K-means clusters\n",
    "xgb_model_kmeans = xgb.XGBClassifier()\n",
    "xgb_model_kmeans.fit(X_train_kmeans, y_train_kmeans)\n",
    "\n",
    "# Predict on the test set for K-means clusters\n",
    "y_pred_kmeans = xgb_model_kmeans.predict(X_test_kmeans)\n",
    "\n",
    "# Compute the accuracy for K-means clusters\n",
    "accuracy_kmeans = accuracy_score(y_test_kmeans, y_pred_kmeans)\n",
    "accuracy_kmeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "429ba263-98b9-4a11-a057-8e82975bc8bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the JS visualization code (for Jupyter Notebook)\n",
    "shap.initjs()\n",
    "\n",
    "# Create a SHAP explainer\n",
    "explainer_kmeans = shap.Explainer(xgb_model_kmeans)\n",
    "\n",
    "# Compute SHAP values for a sample of data (for performance reasons)\n",
    "shap_values_kmeans = explainer_kmeans.shap_values(X_test_kmeans)\n",
    "\n",
    "# Visualize the SHAP values for a specific instance\n",
    "shap.force_plot(explainer_kmeans.expected_value, shap_values_kmeans[0,:], X_test_kmeans.iloc[0,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e3a2090-de53-4c7a-8ee5-20b8b9e68dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "shap.summary_plot(shap_values_kmeans, X_test_kmeans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e2c8ff1-e241-453f-a74c-76745178a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the SHAP values for all instances\n",
    "all_shap_values = shap_values_kmeans\n",
    "features = X_test_kmeans.columns\n",
    "\n",
    "# Create a beeswarm plot for all instances using Plotly\n",
    "traces = []\n",
    "for idx, feature in enumerate(features):\n",
    "    traces.append(\n",
    "        go.Box(\n",
    "            y=[feature] * all_shap_values.shape[0],\n",
    "            x=all_shap_values[:, idx],\n",
    "            name=feature,\n",
    "            boxpoints='all',  # represent all points\n",
    "            jitter=0.5,  # spread out the points for better visibility\n",
    "            pointpos=-2,  # position of the points\n",
    "            marker=dict(size=7, opacity=0.6),\n",
    "            line=dict(width=1),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create layout and figure\n",
    "layout = go.Layout(\n",
    "    title=\"SHAP Values for All Instances\",\n",
    "    xaxis_title=\"SHAP Value\",\n",
    "    yaxis_title=\"Feature\",\n",
    "    boxmode='group'\n",
    ")\n",
    "shap_summary_fig_kmeans = go.Figure(data=traces, layout=layout)\n",
    "\n",
    "shap_summary_fig_kmeans.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "030fa7dd-cfc7-4ff4-9a4e-dca5ae47b2b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute the linkage matrix\n",
    "Z = linkage(data_for_pca, method='ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05ac37db-0ef4-408d-97b9-797447896391",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting a truncated dendrogram\n",
    "plt.figure(figsize=(10, 6))\n",
    "dendrogram(Z, truncate_mode='lastp', p=30, show_leaf_counts=True)\n",
    "plt.title(\"Truncated Dendrogram\")\n",
    "plt.ylabel(\"Euclidean distances\")\n",
    "plt.xlabel(\"Sample index or (Cluster Size)\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abb7b156-a329-4305-8bf6-57c4e1861324",
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters_hierarchical = cut_tree(Z, n_clusters=3).flatten()\n",
    "pc_cl_df['hierarchical_cluster'] = clusters_hierarchical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a58f363-a1be-4791-a996-6ac687847e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2D Visualization using Plotly's graph_objects\n",
    "# Initialize lists to store circle properties for hierarchical clusters\n",
    "circle_centers_hierarchical = []\n",
    "circle_radii_hierarchical = []\n",
    "\n",
    "# Calculate centroid and furthest distance for each hierarchical cluster\n",
    "for cluster_num in pc_cl_df['hierarchical_cluster'].unique():\n",
    "    cluster_data = pc_cl_df[pc_cl_df['hierarchical_cluster'] == cluster_num]\n",
    "    \n",
    "    # Calculate the centroid of the cluster\n",
    "    centroid = [cluster_data['PC1'].mean(), cluster_data['PC2'].mean()]\n",
    "    circle_centers_hierarchical.append(centroid)\n",
    "    \n",
    "    # Calculate the radius as the maximum distance from the centroid\n",
    "    radii = cluster_data.apply(lambda row: distance.euclidean(centroid, [row['PC1'], row['PC2']]), axis=1)\n",
    "    circle_radii_hierarchical.append(radii.max())\n",
    "\n",
    "# Plot the hierarchical clusters and circles\n",
    "fig_h_cl = go.Figure()\n",
    "\n",
    "# Add scatter plot for each cluster\n",
    "for cluster_num in pc_cl_df['hierarchical_cluster'].unique():\n",
    "    cluster_data = pc_cl_df[pc_cl_df['hierarchical_cluster'] == cluster_num]\n",
    "    fig_h_cl.add_trace(go.Scatter(x=cluster_data['PC1'], y=cluster_data['PC2'],\n",
    "                                               mode='markers', name=f'Cluster {cluster_num}'))\n",
    "\n",
    "# Add circle shapes for each cluster\n",
    "for center, radius in zip(circle_centers_hierarchical, circle_radii_hierarchical):\n",
    "    fig_h_cl.add_shape(\n",
    "        type=\"circle\",\n",
    "        xref=\"x\", yref=\"y\",\n",
    "        x0=center[0] - radius, y0=center[1] - radius,\n",
    "        x1=center[0] + radius, y1=center[1] + radius,\n",
    "        opacity=0.2,\n",
    "        fillcolor=\"blue\",\n",
    "        line_color=\"blue\",\n",
    "    )\n",
    "\n",
    "# Add labels and title\n",
    "fig_h_cl.update_layout(title=\"Hierarchical Clusters Visualization\",\n",
    "                                    xaxis_title=\"Principal Component 1\",\n",
    "                                    yaxis_title=\"Principal Component 2\")\n",
    "\n",
    "fig_h_cl.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c4e042e-0451-424c-bcc1-54efe1eaaef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explaining Hierarchical Cluster\n",
    "# Prepare data and labels for hierarchical clusters\n",
    "X = data_for_pca\n",
    "y_hierarchical = pc_cl_df['hierarchical_cluster']\n",
    "\n",
    "# Split data into train and test sets for hierarchical clusters\n",
    "X_train_hierarchical, X_test_hierarchical, y_train_hierarchical, y_test_hierarchical = train_test_split(X, y_hierarchical, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the XGBoost model for hierarchical clusters\n",
    "xgb_model_hierarchical = xgb.XGBClassifier()\n",
    "xgb_model_hierarchical.fit(X_train_hierarchical, y_train_hierarchical)\n",
    "\n",
    "# Predict on the test set for hierarchical clusters\n",
    "y_pred_hierarchical = xgb_model_hierarchical.predict(X_test_hierarchical)\n",
    "\n",
    "# Compute the accuracy for hierarchical clusters\n",
    "accuracy_hierarchical = accuracy_score(y_test_hierarchical, y_pred_hierarchical)\n",
    "accuracy_hierarchical\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04562cda-2b5c-4429-9da6-65303e391444",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an explainer for the XGBoost model\n",
    "explainer_hierarchical = shap.Explainer(xgb_model_hierarchical)\n",
    "\n",
    "# Compute SHAP values for the test set\n",
    "shap_values_hierarchical = explainer_hierarchical.shap_values(X_test_hierarchical)\n",
    "\n",
    "# Generate the SHAP summary plot\n",
    "shap.summary_plot(shap_values_hierarchical, X_test_hierarchical)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "686774d7-265b-4575-a5a4-9828b3ff9c80",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Get the SHAP values for all instances\n",
    "all_shap_values_hierarchical = np.array(shap_values_hierarchical)\n",
    "features = X_test_hierarchical.columns\n",
    "\n",
    "# Create a beeswarm plot for all instances using Plotly\n",
    "traces_hierarchical = []\n",
    "for idx, feature in enumerate(features):\n",
    "    traces_hierarchical.append(\n",
    "        go.Box(\n",
    "            y=[feature] * all_shap_values_hierarchical.shape[0],\n",
    "            x=all_shap_values_hierarchical[:, idx],\n",
    "            name=feature,\n",
    "            boxpoints='all',  # represent all points\n",
    "            jitter=0.5,  # spread out the points for better visibility\n",
    "            pointpos=-2,  # position of the points\n",
    "            marker=dict(size=6, opacity=0.6),  # Larger marker size for visibility\n",
    "            line=dict(width=1),\n",
    "            showlegend=False\n",
    "        )\n",
    "    )\n",
    "\n",
    "# Create layout and figure for hierarchical clustering\n",
    "layout_hierarchical = go.Layout(\n",
    "    title=\"SHAP Values for All Instances (Hierarchical Clustering)\",\n",
    "    xaxis_title=\"SHAP Value\",\n",
    "    yaxis_title=\"Feature\",\n",
    "    boxmode='group'\n",
    ")\n",
    "shap_summary_fig_hierarchical = go.Figure(data=traces_hierarchical, layout=layout_hierarchical)\n",
    "\n",
    "shap_summary_fig_hierarchical.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa723445-3cfb-487b-bc1f-1ebf2a80a1e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_text_arm = \"\"\"\n",
    "In this analysis, Association Rule Mining has been used to discover interesting relationships between variables in the dataset. The rules generated by this method have uncovered patterns and associations that are not readily apparent. This method has provided valuable insights into how different actions are related to each other, enabling us to understand the co-occurrence of different events within the dataset.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85525e96-8e1c-4efc-a679-1efb0c1fc7ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement Association Rule Mining \n",
    "# Aggregating the actions (verbs) for each user (actor_mbox)\n",
    "# We will create a dictionary where each key is a user's email and each value is a list of verbs they have performed\n",
    "\n",
    "# Initialize an empty dictionary to hold the transactions\n",
    "transactions_dict = {}\n",
    "\n",
    "# Loop over each row in the DataFrame\n",
    "for index, row in df.iterrows():\n",
    "    # Use actor_mbox as the key\n",
    "    user = row['actor_mbox']\n",
    "    # Use verb_display_en as the item to add to the transaction\n",
    "    action = row['verb_display_en']\n",
    "    \n",
    "    # If the user is not in the dictionary, add them with a new list containing the action\n",
    "    if user not in transactions_dict:\n",
    "        transactions_dict[user] = [action]\n",
    "    # If the user is already in the dictionary, append the action to their list of actions\n",
    "    else:\n",
    "        transactions_dict[user].append(action)\n",
    "\n",
    "# Convert the dictionary to a list of transactions\n",
    "transactions = list(transactions_dict.values())\n",
    "\n",
    "# Let's see how many transactions we have and the first few of them\n",
    "# len(transactions), transactions[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991acaab-910f-440e-91b4-a494ffda0341",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all actions to strings\n",
    "transactions = [[str(action) for action in user_actions] for user_actions in transactions]\n",
    "\n",
    "# Instantiate the transaction encoder\n",
    "te = TransactionEncoder()\n",
    "\n",
    "# Fit and transform the transactions to a boolean array\n",
    "te_ary = te.fit(transactions).transform(transactions)\n",
    "\n",
    "# Convert the array back to a DataFrame with item names\n",
    "df_transactions = pd.DataFrame(te_ary, columns=te.columns_)\n",
    "\n",
    "# Apply the Apriori algorithm to find frequent itemsets with a support threshold of 0.01 (1%)\n",
    "frequent_itemsets = apriori(df_transactions, min_support=0.01, use_colnames=True)\n",
    "\n",
    "# Display the frequent itemsets\n",
    "frequent_itemsets.sort_values(by='support', ascending=False).head()  # Show top 5 frequent itemsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f70e8a7a-1296-4d81-bcdc-db505b3bfb29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate the association rules\n",
    "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=0.5)\n",
    "\n",
    "# Sort rules by the lift metric in descending order\n",
    "rules = rules.sort_values(by='lift', ascending=False)\n",
    "\n",
    "# Display the top association rules\n",
    "rules.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ae97884-4922-458a-acb1-6aefc0aaf1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'rules' is the DataFrame containing all the association rules\n",
    "\n",
    "# Filter rules by confidence and lift\n",
    "filtered_rules = rules[(rules['confidence'] >= 0.7) & (rules['lift'] >= 1.5)]\n",
    "\n",
    "# Display the filtered rules\n",
    "filtered_rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b800a9a-ef92-4588-abcd-2be01339ac40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'filtered_rules' is your DataFrame containing the filtered rules\n",
    "\n",
    "# Create a scatter plot of support vs confidence\n",
    "fig_a_r_m = go.Figure(data=[\n",
    "    go.Scatter(\n",
    "        x=filtered_rules['support'], \n",
    "        y=filtered_rules['confidence'],\n",
    "        text=filtered_rules['antecedents'].astype(str) + ' -> ' + filtered_rules['consequents'].astype(str),\n",
    "        mode='markers',\n",
    "        marker=dict(\n",
    "            size=filtered_rules['lift'] * 10,  # Multiply by a factor to scale the lift values for better visibility\n",
    "            color=filtered_rules['lift'],\n",
    "            showscale=True,  # Show color scale\n",
    "            colorbar=dict(title='Lift'),\n",
    "        )\n",
    "    )\n",
    "])\n",
    "\n",
    "# Set the title and axis labels\n",
    "fig_a_r_m.update_layout(\n",
    "    title='Association Rules Scatter Plot',\n",
    "    xaxis_title='Support',\n",
    "    yaxis_title='Confidence',\n",
    "    hovermode='closest'  # Show closest point on hover\n",
    ")\n",
    "\n",
    "# Add hover text\n",
    "fig_a_r_m.update_traces(\n",
    "    hovertemplate='Rule: %{text}<br>Support: %{x}<br>Confidence: %{y}<br>Lift: %{marker.color:.2f}'\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig_a_r_m.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27e99a48-ff5d-4c3f-8242-ae998d101e90",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_text_sequence = \"\"\"\n",
    "A sequence diagram tracks the order of learner actions, providing insight into the flow of learning activities. Nodes represent actions, links show progression, and link thickness reflects the frequency of transitions.This helps identify common learning paths and key engagement points in the educational material.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d0a7c7f-2e0d-4780-9647-dfb3e6af52c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sequence Analysis\n",
    "# Convert the timestamp to datetime to ensure proper sorting\n",
    "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
    "\n",
    "# Sort the DataFrame by learner and timestamp\n",
    "df_sorted = df.sort_values(['actor_mbox', 'timestamp'])\n",
    "\n",
    "# Create sequences of verbs for each learner\n",
    "sequences = df_sorted.groupby('actor_mbox')['verb_display_en'].apply(list)\n",
    "\n",
    "# Display the first few sequences\n",
    "sequences.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f663b0-e34e-4b59-baad-c59e18e96c09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the computation is time-consuming, we will reduce the dataset size by sampling a subset of learners.\n",
    "# We will also remove any infrequent verbs to reduce the sequence complexity.\n",
    "\n",
    "# Sampling a subset of learners\n",
    "sampled_sequences = sequences.sample(frac=0.1, random_state=1).tolist()  # Sample 10% of the sequences\n",
    "\n",
    "# Removing infrequent verbs\n",
    "# Let's find the frequency of each verb\n",
    "verb_frequencies = df['verb_display_en'].value_counts()\n",
    "\n",
    "# Filter out verbs that appear less than a certain threshold (e.g., less than 5 times)\n",
    "threshold = 5\n",
    "frequent_verbs = verb_frequencies[verb_frequencies >= threshold].index.tolist()\n",
    "\n",
    "# Now filter the sequences to include only frequent verbs\n",
    "filtered_sequences = [[verb for verb in seq if verb in frequent_verbs] for seq in sampled_sequences]\n",
    "\n",
    "# Re-run the PrefixSpan with the filtered data and higher minimum support\n",
    "ps = PrefixSpan(filtered_sequences)\n",
    "min_support = 5  # Increase the minimum support\n",
    "frequent_sequences = ps.frequent(min_support)\n",
    "# frequent_sequences "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28d3adce-448e-43cf-a104-fc542b74061a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use only the top 10 sequences for visualization\n",
    "top_sequences = sorted(frequent_sequences, reverse=True)[:10]\n",
    "\n",
    "# Convert sequences to abbreviated strings and extract supports\n",
    "sequence_strs = [' -> '.join(seq[:3]) + ('...' if len(seq) > 3 else '') for _, seq in top_sequences]\n",
    "supports = [support for support, _ in top_sequences]\n",
    "\n",
    "# Create a bar chart\n",
    "fig_prefixscan = go.Figure(\n",
    "    data=[go.Bar(\n",
    "        x=sequence_strs,\n",
    "        y=supports\n",
    "    )]\n",
    ")\n",
    "\n",
    "# Update layout for readability\n",
    "fig_prefixscan.update_layout(\n",
    "    title='Top 10 Frequent Sequences',\n",
    "    xaxis_title='Sequence',\n",
    "    yaxis_title='Support Count',\n",
    "    xaxis_tickangle=-45  # Rotate labels for better visibility\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig_prefixscan.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c213eb-fce0-4b18-bf0b-fe37912faee6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the nan value from the unique verbs and verb_indices\n",
    "unique_verbs = pd.Series(df_sorted['verb_display_en'].unique()).sort_values()\n",
    "unique_verbs = unique_verbs.dropna()\n",
    "verb_indices = {verb: i for i, verb in enumerate(unique_verbs)}\n",
    "\n",
    "# Reset the source-target pairs and frequencies without the nan values\n",
    "source_target_freq = defaultdict(int)\n",
    "\n",
    "# Iterate over each sequence and update the source-target frequencies, ensuring no nan values are included\n",
    "for sequence in sequences:\n",
    "    sequence = [verb for verb in sequence if verb in verb_indices]  # Exclude verbs not in verb_indices\n",
    "    for i in range(len(sequence) - 1):\n",
    "        src = verb_indices[sequence[i]]\n",
    "        tgt = verb_indices[sequence[i+1]]\n",
    "        source_target_freq[(src, tgt)] += 1\n",
    "\n",
    "# Now we have the source-target pairs with frequencies, we can create lists for sources, targets, and weights\n",
    "sources = []\n",
    "targets = []\n",
    "weights = []\n",
    "\n",
    "for (src, tgt), freq in source_target_freq.items():\n",
    "    sources.append(src)\n",
    "    targets.append(tgt)\n",
    "    weights.append(freq)\n",
    "\n",
    "# Create a list of verb labels in the same order as the indices\n",
    "labels = list(unique_verbs)\n",
    "\n",
    "# Now we can proceed to create the Sankey diagram with this data.\n",
    "# (sources, targets, weights, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348ee0fc-e3dc-442d-aad4-20c5351d6ea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sankey diagram with Plotly\n",
    "\n",
    "# Create the Sankey diagram figure\n",
    "fig_sankey = go.Figure(data=[go.Sankey(\n",
    "    node=dict(\n",
    "        pad=15,\n",
    "        thickness=20,\n",
    "        line=dict(color=\"black\", width=0.5),\n",
    "        label=labels\n",
    "    ),\n",
    "    link=dict(\n",
    "        source=sources,\n",
    "        target=targets,\n",
    "        value=weights\n",
    "    )\n",
    ")])\n",
    "\n",
    "# Set the title and layout\n",
    "fig_sankey.update_layout(title_text='Learner Actions Sequence Sankey Diagram', font_size=10)\n",
    "\n",
    "# Show the figure\n",
    "fig_sankey.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12cabfd6-683a-4157-9b92-b32285293a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "info_text_time_based_analysis=\"\"\"\n",
    "In our Time-Based Patterns Analysis, we delved into the temporal dynamics of learners' activities, focusing on the timing and duration of interactions. By sorting the xAPI data chronologically for each learner, we calculated the time intervals between consecutive actions, allowing us to identify periods of intense activity as well as pauses in engagement. This analysis was instrumental in distinguishing between individual sessions, where we considered any gap longer than one hour as the beginning of a new session. By aggregating these time differences across different types of interactions (verbs), we gained insights into the rhythms of learning behaviors. For instance, certain actions like 'accessed' or 'attempted' may have shorter intervals, suggesting rapid engagement, whereas others, such as 'completed', could indicate longer periods of focus. The visualization of these temporal patterns aided in understanding the ebb and flow of learners' engagement over time, providing a nuanced view of the learning process beyond mere activity counts.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad624b88-e6d5-4854-9c7c-fcbb26d851cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-Based Patterns Analysis\n",
    "# Group the data by learner and sort by timestamp\n",
    "df_sorted = df.sort_values(['actor_mbox', 'timestamp'])\n",
    "\n",
    "# Calculate the time difference between subsequent actions for each user\n",
    "df_sorted['time_diff'] = df_sorted.groupby('actor_mbox')['timestamp'].diff().dt.total_seconds() / 3600  # Convert to hours\n",
    "\n",
    "# Now, we will consider a new session if the time difference exceeds 1 hour\n",
    "# We create a session identifier that increments every time there is a break of more than 1 hour\n",
    "df_sorted['session_id'] = (df_sorted['time_diff'] > 1).astype(int).cumsum()\n",
    "\n",
    "# Finally, we calculate the duration in hours within each session\n",
    "df_sorted['duration_within_session_hours'] = df_sorted.groupby(['actor_mbox', 'session_id'])['timestamp'].diff().dt.total_seconds() / 3600\n",
    "\n",
    "# Fill NaN values with zeros for the first action in each session\n",
    "df_sorted['duration_within_session_hours'] = df_sorted['duration_within_session_hours'].fillna(0)\n",
    "\n",
    "# Let's take a look at the result\n",
    "df_sorted[['actor_mbox', 'timestamp', 'time_diff', 'session_id', 'duration_within_session_hours']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc8521ff-2c11-4353-8cc5-07c0983d0ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the average time difference for each verb within the sessions, ignoring the first action (where time_diff would be NaN)\n",
    "avg_time_diff_per_verb_within_session = df_sorted[df_sorted['duration_within_session_hours'] > 0].groupby('verb_display_en')['duration_within_session_hours'].mean().reset_index()\n",
    "\n",
    "# Visualize the average time difference for each verb using a bar chart\n",
    "fig_time_based_patterns_within_session = px.bar(avg_time_diff_per_verb_within_session, x='verb_display_en', y='duration_within_session_hours',\n",
    "             title='Average Time Difference Between Actions for Each Verb Within Sessions',\n",
    "             labels={'verb_display_en': 'Verb', 'duration_within_session_hours': 'Average Time Difference (hours)'},\n",
    "             color='duration_within_session_hours',\n",
    "             color_continuous_scale=px.colors.sequential.Viridis)\n",
    "\n",
    "# Rotate the x-axis labels for better readability\n",
    "fig_time_based_patterns_within_session.update_layout(xaxis_tickangle=-45)\n",
    "\n",
    "# Show the figure\n",
    "fig_time_based_patterns_within_session.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "301c001c-e4cd-4625-8f0f-015291214c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Survival analysis with Lifeline\n",
    "\n",
    "# Identify the end event, assuming 'completed' is the end event\n",
    "end_event = 'marked-completion'\n",
    "df_sorted['event_occurred'] = df_sorted['verb_display_en'].apply(lambda x: 1 if x == end_event else 0)\n",
    "\n",
    "# For each learner, keep only the record with the end event or the last record if the end event hasn't occurred\n",
    "df_survival = df_sorted.sort_values(by=['actor_mbox', 'timestamp']).groupby('actor_mbox').last().reset_index()\n",
    "\n",
    "# Fit the Kaplan-Meier curve\n",
    "kmf = KaplanMeierFitter()\n",
    "kmf.fit(df_survival['duration_within_session_hours'], event_observed=df_survival['event_occurred'])\n",
    "\n",
    "# Extract the survival function data\n",
    "kmf_data = kmf.survival_function_\n",
    "\n",
    "# Create a Plotly figure\n",
    "fig_lifelines = go.Figure()\n",
    "\n",
    "# Add the survival curve to the figure\n",
    "fig_lifelines.add_trace(go.Scatter(x=kmf_data.index, y=kmf_data[\"KM_estimate\"],\n",
    "                         mode='lines', name='Survival curve'))\n",
    "\n",
    "# Add labels and title\n",
    "fig_lifelines.update_layout(\n",
    "    title=\"Kaplan-Meier Survival Curve (with 'marked-completion' as end event)\",\n",
    "    xaxis_title=\"Time (Hours)\",\n",
    "    yaxis_title=\"Survival Probability\",\n",
    "    template=\"plotly_white\"\n",
    ")\n",
    "\n",
    "# Show the figure\n",
    "fig_lifelines.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4aee6a-7aa8-4f7d-8a28-fe52e2b5defa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heuristics Miner is a process mining algorithm provided by the pm4py\n",
    "# First, we will drop rows where 'verb_display_en' is NaN since these are essential for process mining.\n",
    "df_clean = df.dropna(subset=['verb_display_en'])\n",
    "\n",
    "# Now let's ensure that all 'verb_display_en' values are strings, even if they were NaN before.\n",
    "df_clean['verb_display_en'] = df_clean['verb_display_en'].astype(str)\n",
    "\n",
    "# Check if there are any NaN values left in the 'verb_display_en' column\n",
    "nan_in_verb_display = df_clean['verb_display_en'].isnull().sum()\n",
    "\n",
    "# Prepare the DataFrame for Heuristics Miner again\n",
    "df_heuristics_clean = df_clean[['actor_mbox', 'verb_display_en', 'timestamp']].copy()\n",
    "df_heuristics_clean.rename(columns={\n",
    "    'actor_mbox': 'case:concept:name',\n",
    "    'verb_display_en': 'concept:name',\n",
    "    'timestamp': 'time:timestamp'\n",
    "}, inplace=True)\n",
    "\n",
    "# Check the data types to ensure they're correct\n",
    "data_types = df_heuristics_clean.dtypes\n",
    "\n",
    "df_heuristics_clean.head(), nan_in_verb_display, data_types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91f730f-c421-4c26-82b0-676f07f8beef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the DataFrame to an event log\n",
    "log = log_converter.apply(df_heuristics_clean)\n",
    "\n",
    "# Discover the process model using Heuristics Miner\n",
    "heu_net = heuristics_miner.apply_heu(log)\n",
    "\n",
    "# Print all attributes and methods of the HeuristicsNet object\n",
    "print(dir(heu_net))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1f6c9c-cbd2-425c-9a34-eadeadae1ffb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Access the nodes (activities) in the HeuristicsNet\n",
    "activities = heu_net.activities\n",
    "\n",
    "# Access the dependencies in the HeuristicsNet\n",
    "dependencies = heu_net.dependency_matrix\n",
    "\n",
    "# Print activities and their occurrences\n",
    "# print(\"Activities and Occurrences:\")\n",
    "# for activity, occurrence in heu_net.activities_occurrences.items():\n",
    "#    print(f\"Activity: {activity}, Occurrences: {occurrence}\")\n",
    "\n",
    "# Print dependencies\n",
    "# print(\"\\nDependencies Matrix:\")\n",
    "# print(dependencies)\n",
    "\n",
    "# You can also access the Directly Follows Graph (DFG)\n",
    "dfg = heu_net.dfg\n",
    "# print(\"\\nDirectly Follows Graph:\")\n",
    "# for (activity_from, activity_to), value in dfg.items():\n",
    "#    print(f\"From: {activity_from}, To: {activity_to}, Value: {value}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "896d1aaf-fb2a-43e1-adb8-3f5f58fc6ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize with Plotly\n",
    "# We'll keep it simple and just plot a circular layout for the nodes\n",
    "node_coords = {}\n",
    "theta = 0\n",
    "radius = 1\n",
    "for i, activity in enumerate(activities):\n",
    "    theta += 2 * 3.14159 / len(activities)  # distribute nodes evenly on a circle\n",
    "    x = radius * 3 * (i % 2) * (-1 if i % 4 < 2 else 1)  # alternating x for visibility\n",
    "    y = radius * (len(activities) / 4 - i // 2)  # stacked y for visibility\n",
    "    node_coords[activity] = (x, y)\n",
    "\n",
    "# Initialize figure\n",
    "fig_pm4py = go.Figure()\n",
    "\n",
    "# Add edges as lines\n",
    "for (activity_from, activity_to), value in dfg.items():\n",
    "    if activity_from in node_coords and activity_to in node_coords:\n",
    "        fig_pm4py.add_trace(go.Scatter(\n",
    "            x=[node_coords[activity_from][0], node_coords[activity_to][0]],\n",
    "            y=[node_coords[activity_from][1], node_coords[activity_to][1]],\n",
    "            mode='lines',\n",
    "            line=dict(width=2, color='blue'),\n",
    "            hoverinfo='none'\n",
    "        ))\n",
    "\n",
    "# Add nodes as markers\n",
    "for activity, pos in node_coords.items():\n",
    "    fig_pm4py.add_trace(go.Scatter(\n",
    "        x=[pos[0]],\n",
    "        y=[pos[1]],\n",
    "        mode='markers+text',\n",
    "        marker=dict(size=10, color='red'),\n",
    "        text=activity,\n",
    "        textposition=\"bottom center\"\n",
    "    ))\n",
    "\n",
    "# Update layout\n",
    "fig_pm4py.update_layout(\n",
    "    title='Heuristics Net Visualization with pm4py',\n",
    "    height=800,  # or any other value that suits your needs\n",
    "    showlegend=False,\n",
    "    xaxis=dict(showgrid=False, zeroline=False, showticklabels=False),\n",
    "    yaxis=dict(showgrid=False, zeroline=False, showticklabels=False)\n",
    ")\n",
    "\n",
    "# Show figure\n",
    "fig_pm4py.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a4d4824-7910-4dda-b695-6ed9d1a00b28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'verb_display_en' column\n",
    "verb_display_en_counts = df['verb_display_en'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "fig_1 = px.bar(verb_display_en_counts, x=verb_display_en_counts.index, y=verb_display_en_counts.values, title='Distribution of Verbs', labels={'x': 'Verbs', 'y': 'Count'})\n",
    "\n",
    "# Show the plot\n",
    "fig_1.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "982e0372-038b-4abd-8491-7cc276e0f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'obj_type' column\n",
    "obj_type_counts = df['obj_type'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "fig_2 = px.pie(obj_type_counts, names=obj_type_counts.index, values=obj_type_counts.values, title='Distribution of Activities')\n",
    "\n",
    "# Show the plot\n",
    "fig_2.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eebbca4a-38d2-4416-9870-fa7d4f147f88",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'obj_type' column\n",
    "platform_counts = df['platform'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "fig_3 = px.pie(platform_counts, names=platform_counts.index, values=platform_counts.values, title='Statements per Platform')\n",
    "\n",
    "# Show the plot\n",
    "fig_3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "479cfc94-5cc4-44b7-bb74-3fc88c8446d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'language' column\n",
    "language_counts = df['language'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "fig_4 = px.pie(language_counts, names=language_counts.index, values=language_counts.values, title='Languages')\n",
    "\n",
    "# Show the plot\n",
    "fig_4.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efd8f0f3-4e24-4eef-983c-85e90f88c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily statements per day\n",
    "daily_counts = df.groupby('date').size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708fa163-5706-4fab-9827-90eb0ddd79e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute trendline\n",
    "z = np.polyfit(range(len(daily_counts['count'])), daily_counts['count'], 1)\n",
    "p = np.poly1d(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a184516-a96a-4019-abc4-7e73cccc3a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_5 = go.Figure()\n",
    "\n",
    "fig_5.add_trace(go.Scatter(x=daily_counts['date'], y=daily_counts['count'], mode='lines+markers', name='Original Data',\n",
    "                         line=dict(dash='dashdot')))\n",
    "\n",
    "# Trendline\n",
    "fig_5.add_trace(go.Scatter(x=daily_counts['date'], y=p(range(len(daily_counts['count']))), mode='lines', name='Trendline',\n",
    "                         line=dict(color='red')))\n",
    "\n",
    "fig_5.update_layout(title='Statements per Day',\n",
    "                  xaxis_title='Date',\n",
    "                  yaxis_title='Count')\n",
    "# Update the layout to add the range slider\n",
    "fig_5.update_layout(\n",
    "    xaxis=dict(\n",
    "        rangeslider=dict(\n",
    "            visible=True\n",
    "        ),\n",
    "        type=\"date\"\n",
    "    )\n",
    ")\n",
    "fig_5.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb7fa6b4-d0f1-440b-8fac-6ed8d846745d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get value counts of the 'timeframe' column\n",
    "timeframe_counts = df['timeframe'].value_counts()\n",
    "\n",
    "# Create a bar chart\n",
    "fig_6 = px.pie(timeframe_counts, names=timeframe_counts.index, values=timeframe_counts.values, title='Stetements per Timeframe')\n",
    "\n",
    "# Show the plot\n",
    "fig_6.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "602305a7-ce93-4ab0-aea0-2a4ce8ccff4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define valid username and password pairs\n",
    "VALID_USERNAME_PASSWORD_PAIRS = {\n",
    "    'admin': 'password'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ee12148-f7a5-43bd-9e73-6636cc7b922c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dropdown options from the 'platform' column\n",
    "platform_options = df['platform'].unique()\n",
    "\n",
    "# Dropdown options from the 'course' column\n",
    "object_options = df['obj_def_name_en'].unique()\n",
    "\n",
    "# Dropdown options from the 'actor_mbox' column\n",
    "user_options = df['actor_mbox'].unique()\n",
    "\n",
    "# Calculate the total number of unique users\n",
    "total_unique_users = len(df['actor_mbox'].unique())\n",
    "\n",
    "# Calculate the total number of instances which we collect data\n",
    "total_instances = len(df['platform'].unique())\n",
    "\n",
    "# Calculate the total number of statements which we collect data\n",
    "total_statements = len(df['statement_ID'].unique())\n",
    "\n",
    "# Calculate the total number of objects which we collect data\n",
    "total_objects = len(df['obj_def_name_en'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae370676-4ced-4b3e-a70c-c3ba0625ddcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "app = dash.Dash(external_stylesheets=[dbc.themes.MORPH])\n",
    "\n",
    "# the style arguments for the sidebar. We use position:fixed and a fixed width\n",
    "SIDEBAR_STYLE = {\n",
    "    \"position\": \"fixed\",\n",
    "    \"top\": 0,\n",
    "    \"left\": 0,\n",
    "    \"bottom\": 0,\n",
    "    \"width\": \"16rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "    \"background-color\": \"#f8f9fa\",\n",
    "}\n",
    "\n",
    "# the styles for the main content position it to the right of the sidebar and\n",
    "# add some padding.\n",
    "CONTENT_STYLE = {\n",
    "    \"margin-left\": \"18rem\",\n",
    "    \"margin-right\": \"2rem\",\n",
    "    \"padding\": \"2rem 1rem\",\n",
    "}\n",
    "\n",
    "sidebar = html.Div(\n",
    "    [\n",
    "        html.H2(\"Learning Analytics\", className=\"display-4 center\"),\n",
    "        html.Hr(),\n",
    "        html.P(\n",
    "            \"A Dashboard for presenting the data extracted from TRAX LRS\", className=\"lead center\"\n",
    "        ),\n",
    "        dbc.Nav(\n",
    "            [\n",
    "                dbc.NavLink(\"Home\", href=\"/\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Metrics per Instance\", href=\"/instance\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Metrics per Object\", href=\"/object\", active=\"exact\"),\n",
    "                dbc.NavLink(\"Metrics per User\", href=\"/user\", active=\"exact\"),\n",
    "            ],\n",
    "            vertical=True,\n",
    "            pills=True,\n",
    "        ),\n",
    "    ],\n",
    "    style=SIDEBAR_STYLE,\n",
    ")\n",
    "\n",
    "content = html.Div(id=\"page-content\", style=CONTENT_STYLE)\n",
    "\n",
    "# Create a statistic card for the total unique users\n",
    "stat_card_unique_users = dbc.Card([\n",
    "    dbc.CardBody([\n",
    "        html.H4(\"Total Users\", className=\"card-title\"),\n",
    "        html.H2(str(total_unique_users), className=\"card-subtitle\"),\n",
    "    ])\n",
    "], color=\"success\", inverse=True)\n",
    "\n",
    "# Create a statistic card for the total instances\n",
    "stat_card_instances = dbc.Card([\n",
    "    dbc.CardBody([\n",
    "        html.H4(\"Total Instances\", className=\"card-title\"),\n",
    "        html.H2(str(total_instances), className=\"card-subtitle\"),\n",
    "    ])\n",
    "], color=\"info\", inverse=True)\n",
    "\n",
    "# Create a statistic card for the total statements\n",
    "stat_card_statements = dbc.Card([\n",
    "    dbc.CardBody([\n",
    "        html.H4(\"Total Statements\", className=\"card-title\"),\n",
    "        html.H2(str(total_statements), className=\"card-subtitle\"),\n",
    "    ])\n",
    "], color=\"warning\", inverse=True)\n",
    "\n",
    "# Create a statistic card for the total objects\n",
    "stat_card_objects = dbc.Card([\n",
    "    dbc.CardBody([\n",
    "        html.H4(\"Total Objects\", className=\"card-title\"),\n",
    "        html.H2(str(total_objects), className=\"card-subtitle\"),\n",
    "    ])\n",
    "], color=\"danger\", inverse=True)\n",
    "\n",
    "# Use BasicAuth to wrap around the app and handle authentication\n",
    "auth = dash_auth.BasicAuth(\n",
    "    app,\n",
    "    VALID_USERNAME_PASSWORD_PAIRS\n",
    ")\n",
    "\n",
    "app.layout = html.Div([dcc.Location(id=\"url\"), sidebar, content])\n",
    "\n",
    "\n",
    "@app.callback(Output(\"page-content\", \"children\"), [Input(\"url\", \"pathname\")])\n",
    "def render_page_content(pathname):\n",
    "    if pathname == \"/\":\n",
    "        return (\n",
    "        dbc.Container(\n",
    "        [html.H1(\"Overview\", className=\"mb-4\"),\n",
    "        html.Hr(),  # This is the horizontal line\n",
    "        dbc.Row([\n",
    "        dbc.Col(stat_card_unique_users, width=6),\n",
    "        dbc.Col(stat_card_instances, width=6),\n",
    "        ],className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row([\n",
    "        dbc.Col(stat_card_statements, width=6),\n",
    "        dbc.Col(stat_card_objects, width=6),\n",
    "        ],className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='statements-per-day-all', figure=fig_5), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='distribution-of-verbs-all', figure=fig_1), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\", \n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-boxplot-verbs', figure=fig_boxplot_verbs), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\", \n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-boxplot-basic', figure=fig_boxplot_basic), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\", \n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='distribution-per-activity-all', figure=fig_2), width=6),\n",
    "                dbc.Col(dcc.Graph(id='statements-per-platform-all', figure=fig_3), width=6),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='languages-all', figure=fig_4), width=6),\n",
    "                dbc.Col(dcc.Graph(id='statements-per-timeframe-all', figure=fig_6), width=6),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dbc.Card(\n",
    "                    [\n",
    "                        dbc.CardHeader(\"Clustering Analysis\", className=\"font-weight-bold text-center\"),\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.P(info_text_clustering, className=\"card-text\"),\n",
    "                                html.Br(),\n",
    "                                html.P(info_text_shap, className=\"card-text\")\n",
    "                            ]\n",
    "                        ),\n",
    "                    ],\n",
    "                    style={\"margin-bottom\": \"20px\", \"marginTop\": \"20px\", \"backgroundColor\": \"#f8f9fa\"},\n",
    "                    className=\"w-100\"\n",
    "                ),\n",
    "                width=12\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-dbscan', figure=fig_dbscan), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-elbow', figure=elbow_fig), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-kmeans', figure=fig_kmeans), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-shap-kmeans', figure=shap_summary_fig_kmeans), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-hierarchical', figure=fig_h_cl), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-shap-hierarchical', figure=shap_summary_fig_hierarchical), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dbc.Card(\n",
    "                    [\n",
    "                        dbc.CardHeader(\"Association Rule Mining Insights\", className=\"font-weight-bold text-center\"),\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.P(info_text_arm, className=\"card-text\")\n",
    "                            ]\n",
    "                        ),\n",
    "                    ],\n",
    "                    style={\"margin-bottom\": \"20px\", \"marginTop\": \"20px\", \"backgroundColor\": \"#f8f9fa\"},\n",
    "                    className=\"w-100\"\n",
    "                ),\n",
    "                width=12\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-a-r-m', figure=fig_a_r_m), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(\n",
    "                    dbc.Button(\n",
    "                        \"Association Rules Mining CSV\", \n",
    "                        id=\"btn_csv\", \n",
    "                        style={\"backgroundColor\": \"navy\", \"color\": \"white\"}, # Navy blue button with white text\n",
    "                        className=\"mx-auto d-block\"  # Center the button\n",
    "                    ),\n",
    "                    width=12  # Take up the full width to center the button\n",
    "                ),\n",
    "            ],\n",
    "            className=\"mb-4\",  # Add some margin below the row\n",
    "        ),\n",
    "        dcc.Download(id=\"download-dataframe-csv\"),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dbc.Card(\n",
    "                    [\n",
    "                        dbc.CardHeader(\"Sequence Insights\", className=\"font-weight-bold text-center\"),\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.P(info_text_sequence, className=\"card-text\")\n",
    "                            ]\n",
    "                        ),\n",
    "                    ],\n",
    "                    style={\"margin-bottom\": \"20px\", \"marginTop\": \"20px\", \"backgroundColor\": \"#f8f9fa\"},\n",
    "                    className=\"w-100\"\n",
    "                ),\n",
    "                width=12\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-prefixscan', figure=fig_prefixscan), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-sankey', figure=fig_sankey), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            dbc.Col(\n",
    "                dbc.Card(\n",
    "                    [\n",
    "                        dbc.CardHeader(\"Time-Based Patterns Analysis\", className=\"font-weight-bold text-center\"),\n",
    "                        dbc.CardBody(\n",
    "                            [\n",
    "                                html.P(info_text_time_based_analysis, className=\"card-text\")\n",
    "                            ]\n",
    "                        ),\n",
    "                    ],\n",
    "                    style={\"margin-bottom\": \"20px\", \"marginTop\": \"20px\", \"backgroundColor\": \"#f8f9fa\"},\n",
    "                    className=\"w-100\"\n",
    "                ),\n",
    "                width=12\n",
    "            )\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-time-based-patterns-within-session', figure=fig_time_based_patterns_within_session), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-lifelines', figure=fig_lifelines), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        ),\n",
    "        dbc.Row(\n",
    "            [\n",
    "                dbc.Col(dcc.Graph(id='fig-pm4py', figure=fig_pm4py), width=12),\n",
    "            ],\n",
    "            className=\"mb-4\",\n",
    "        )\n",
    "    ], fluid=True  # Set to True for a full width container\n",
    "        ))\n",
    "    elif pathname == \"/instance\":\n",
    "        return(\n",
    "            dbc.Container([\n",
    "            html.H1(\"Platform Metrics Visualization\", className=\"mb-4\"),\n",
    "            html.Hr(),         \n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    html.Label(\"Select Platform:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"platform-dropdown\",\n",
    "                        options=[{'label': platform, 'value': platform} for platform in platform_options],\n",
    "                        value=[platform_options[0]],\n",
    "                        multi=True  # allow multiple selection\n",
    "                    )\n",
    "                ], width=4)\n",
    "            ], className=\"mb-4\"),\n",
    "            dbc.Row([\n",
    "            dbc.Col(id='stat-card-unique-users-platform', width=4),\n",
    "            dbc.Col(id='stat-card-statements-platform', width=4),\n",
    "            dbc.Col(id='stat-card-objects-platform', width=4),\n",
    "            ],className=\"mb-4\",\n",
    "            ), \n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-day-platform'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='distribution-of-verbs-platform'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\", \n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='languages-platform'), width=6),\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-timeframe-platform'), width=6),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='distribution-per-activity-platform'), width=6),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            )\n",
    "        ])\n",
    "        )\n",
    "    elif pathname == \"/object\":\n",
    "            return(\n",
    "            dbc.Container([\n",
    "            html.H1(\"Object Metrics Visualization\", className=\"mb-4\"),\n",
    "            html.Hr(),  # This is the horizontal line \n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    html.Label(\"Select Object:\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"object-dropdown\",\n",
    "                        options=[{'label': object, 'value': object} for object in object_options],\n",
    "                        value=[object_options[0]],\n",
    "                        multi=True  # allow multiple selection\n",
    "                    )\n",
    "                ], width=4)\n",
    "            ], className=\"mb-4\"),\n",
    "            dbc.Row([\n",
    "            dbc.Col(id='stat-card-unique-users-object', width=6),\n",
    "            dbc.Col(id='stat-card-statements-object', width=6),\n",
    "            ],className=\"mb-4\",\n",
    "            ), \n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-day-object'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='distribution-of-verbs-object'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\", \n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='languages-object'), width=6),\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-timeframe-object'), width=6),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='distribution-per-activity-object'), width=6),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            )\n",
    "        ])\n",
    "            )\n",
    "    elif pathname == \"/user\":\n",
    "            return(\n",
    "            dbc.Container([\n",
    "            html.H1(\"User Metrics Visualization\", className=\"mb-4\"),\n",
    "            html.Hr(),  # This is the horizontal line \n",
    "            dbc.Row([\n",
    "                dbc.Col([\n",
    "                    html.Label(\"Select User(with email):\"),\n",
    "                    dcc.Dropdown(\n",
    "                        id=\"user-dropdown\",\n",
    "                        options=[{'label': user, 'value': user} for user in user_options],\n",
    "                        value=[user_options[0]],\n",
    "                        multi=True  # allow multiple selection\n",
    "                    )\n",
    "                ], width=4)\n",
    "            ], className=\"mb-4\"),\n",
    "            dbc.Row([\n",
    "            dbc.Col(id='stat-card-instances-user', width=4),\n",
    "            dbc.Col(id='stat-card-statements-user', width=4),\n",
    "            dbc.Col(id='stat-card-objects-user', width=4),\n",
    "            ],className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-day-user'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='distribution-of-verbs-user'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\", \n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='verbs-over-time-user'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\", \n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='time-spent-user'), width=12),\n",
    "                ],\n",
    "                className=\"mb-4\", \n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='languages-user'), width=6),\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-timeframe-user'), width=6),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row(\n",
    "                [\n",
    "                    dbc.Col(dcc.Graph(id='distribution-per-activity-user'), width=6),\n",
    "                    dbc.Col(dcc.Graph(id='statements-per-platform-user'), width=6),\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            ),\n",
    "            dbc.Row([\n",
    "                dbc.Col(id=\"user-data-table\")\n",
    "                ],\n",
    "                className=\"mb-4\",\n",
    "            )\n",
    "        ])\n",
    "            )\n",
    "    # If the user tries to reach a different page, return a 404 message\n",
    "    return html.Div(\n",
    "        [\n",
    "            html.H1(\"404: Not found\", className=\"text-danger\"),\n",
    "            html.Hr(),\n",
    "            html.P(f\"The pathname {pathname} was not recognised...\"),\n",
    "        ],\n",
    "        className=\"p-3 bg-light rounded-3\",\n",
    "    )\n",
    "\n",
    "# Callback for the button\n",
    "@app.callback(\n",
    "    Output(\"download-dataframe-csv\", \"data\"),\n",
    "    Input(\"btn_csv\", \"n_clicks\"),\n",
    "    prevent_initial_call=True\n",
    ")\n",
    "def download_csv(n_clicks):\n",
    "    return dcc.send_data_frame(filtered_rules.to_csv, \"filtered_rules.csv\")\n",
    "\n",
    "# Callbacks to update the platform plots\n",
    "@app.callback(\n",
    "    [Output(\"distribution-of-verbs-platform\", \"figure\"),\n",
    "     Output(\"statements-per-day-platform\", \"figure\"),\n",
    "     Output(\"distribution-per-activity-platform\", \"figure\"),\n",
    "     Output(\"languages-platform\", \"figure\"),\n",
    "     Output(\"statements-per-timeframe-platform\", \"figure\"),\n",
    "     Output(\"stat-card-unique-users-platform\", \"children\"),\n",
    "     Output(\"stat-card-statements-platform\", \"children\"),\n",
    "     Output(\"stat-card-objects-platform\", \"children\")],\n",
    "    [Input(\"platform-dropdown\", \"value\")\n",
    "    ]\n",
    ")\n",
    "def update_graphs_platform(selected_platform):\n",
    "    # Filter data based on selected platform\n",
    "    filtered_data_platform = df[df['platform'].isin(selected_platform)]\n",
    "    unique_users_platform_count = len(filtered_data_platform['actor_mbox'].unique())\n",
    "    statements_platform_count = len(filtered_data_platform['statement_ID'].unique())\n",
    "    objects_platform_count = len(filtered_data_platform['obj_def_name_en'].unique())\n",
    "\n",
    "    \n",
    "    # Graphs per Platform\n",
    "    distribution_of_verbs_platform_fig = px.bar(filtered_data_platform, x=filtered_data_platform['verb_display_en'].value_counts().index,\n",
    "                      y=filtered_data_platform['verb_display_en'].value_counts().values,\n",
    "                      labels={'x': 'Verb', 'y': 'Count'},\n",
    "                      title='Distribution of Verbs')\n",
    "\n",
    "    # Daily statements per day\n",
    "    daily_counts = filtered_data_platform.groupby('date').size().reset_index(name='count')\n",
    "\n",
    "    statements_per_day_platform_fig = go.Figure()\n",
    "\n",
    "    statements_per_day_platform_fig.add_trace(go.Scatter(x=daily_counts['date'], y=daily_counts['count'], mode='lines+markers', name='Time Series',\n",
    "                             line=dict(dash='dashdot')))\n",
    "    \n",
    "    statements_per_day_platform_fig.update_layout(title='Statements per Day',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Count')\n",
    "    # Update the layout to add the range slider\n",
    "    statements_per_day_platform_fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    distribution_per_activity_platform_fig = px.pie(filtered_data_platform , names='obj_type', title='Distribution per Activity')\n",
    "    languages_platform_fig = px.pie(filtered_data_platform , names='language', title='Language Distribution')\n",
    "    statements_per_timeframe_platform_fig = px.pie(filtered_data_platform , names='timeframe', title='Statements per Timeframe')\n",
    "\n",
    "    stat_card_unique_users_platform = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Users\", className=\"card-title\"),\n",
    "            html.H2(str(unique_users_platform_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"success\", inverse=True)\n",
    "\n",
    "    stat_card_statements_platform = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Statements\", className=\"card-title\"),\n",
    "            html.H2(str(statements_platform_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"warning\", inverse=True)\n",
    "\n",
    "    stat_card_objects_platform = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Objects\", className=\"card-title\"),\n",
    "            html.H2(str(objects_platform_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"danger\", inverse=True)\n",
    "    \n",
    "    return distribution_of_verbs_platform_fig, statements_per_day_platform_fig, distribution_per_activity_platform_fig, languages_platform_fig, statements_per_timeframe_platform_fig,  stat_card_unique_users_platform, stat_card_statements_platform, stat_card_objects_platform\n",
    "\n",
    "# Callbacks to update the object plots\n",
    "@app.callback(\n",
    "    [Output(\"distribution-of-verbs-object\", \"figure\"),\n",
    "     Output(\"statements-per-day-object\", \"figure\"),\n",
    "     Output(\"distribution-per-activity-object\", \"figure\"),\n",
    "     Output(\"languages-object\", \"figure\"),\n",
    "     Output(\"statements-per-timeframe-object\", \"figure\"),\n",
    "     Output(\"stat-card-unique-users-object\", \"children\"),\n",
    "     Output(\"stat-card-statements-object\", \"children\")],\n",
    "    [Input(\"object-dropdown\", \"value\")\n",
    "    ]\n",
    ")\n",
    "def update_graphs_object(selected_object):\n",
    "    # Filter data based on selected platform\n",
    "    filtered_data_object = df[df['obj_def_name_en'].isin(selected_object)]\n",
    "    unique_users_object_count = len(filtered_data_object['actor_mbox'].unique())\n",
    "    statements_object_count = len(filtered_data_object['statement_ID'].unique())\n",
    "    \n",
    "    # Graphs per Platform\n",
    "    distribution_of_verbs_object_fig = px.bar(filtered_data_object, x=filtered_data_object['verb_display_en'].value_counts().index,\n",
    "                      y=filtered_data_object['verb_display_en'].value_counts().values,\n",
    "                      labels={'x': 'Verb', 'y': 'Count'},\n",
    "                      title='Distribution of Verbs')\n",
    "\n",
    "    # Daily statements per day\n",
    "    daily_counts = filtered_data_object.groupby('date').size().reset_index(name='count')\n",
    "\n",
    "    statements_per_day_object_fig = go.Figure()\n",
    "\n",
    "    statements_per_day_object_fig.add_trace(go.Scatter(x=daily_counts['date'], y=daily_counts['count'], mode='lines+markers', name='Time Series',\n",
    "                             line=dict(dash='dashdot')))\n",
    "    \n",
    "    statements_per_day_object_fig.update_layout(title='Statements per Day',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Count')\n",
    "    # Update the layout to add the range slider\n",
    "    statements_per_day_object_fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "    \n",
    "    distribution_per_activity_object_fig = px.pie(filtered_data_object , names='obj_type', title='Distribution per Activity')\n",
    "    languages_object_fig = px.pie(filtered_data_object , names='language', title='Language Distribution')\n",
    "    statements_per_timeframe_object_fig = px.pie(filtered_data_object , names='timeframe', title='Statements per Timeframe')\n",
    "\n",
    "    stat_card_unique_users_object = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Users\", className=\"card-title\"),\n",
    "            html.H2(str(unique_users_object_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"success\", inverse=True)\n",
    "\n",
    "    stat_card_statements_object = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Statements\", className=\"card-title\"),\n",
    "            html.H2(str(statements_object_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"warning\", inverse=True)\n",
    "    \n",
    "    return distribution_of_verbs_object_fig, statements_per_day_object_fig, distribution_per_activity_object_fig, languages_object_fig, statements_per_timeframe_object_fig, stat_card_unique_users_object, stat_card_statements_object\n",
    "\n",
    "# Callbacks to update the user plots\n",
    "@app.callback(\n",
    "    [Output(\"distribution-of-verbs-user\", \"figure\"),\n",
    "     Output(\"statements-per-day-user\", \"figure\"),\n",
    "     Output(\"verbs-over-time-user\", \"figure\"),\n",
    "     Output(\"time-spent-user\", \"figure\"),\n",
    "     Output(\"distribution-per-activity-user\", \"figure\"),\n",
    "     Output(\"languages-user\", \"figure\"),\n",
    "     Output(\"statements-per-timeframe-user\", \"figure\"),\n",
    "     Output(\"statements-per-platform-user\", \"figure\"),\n",
    "     Output(\"stat-card-instances-user\", \"children\"),\n",
    "     Output(\"stat-card-statements-user\", \"children\"),\n",
    "     Output(\"stat-card-objects-user\", \"children\"),\n",
    "     Output(\"user-data-table\", \"children\")\n",
    "    ],\n",
    "    [Input(\"user-dropdown\", \"value\")\n",
    "    ]\n",
    ")\n",
    "def update_graphs_user(selected_user):\n",
    "    # Filter data based on selected learner\n",
    "    filtered_data_user = df[df['actor_mbox'].isin(selected_user)]\n",
    "    instances_user_count = len(filtered_data_user['platform'].unique())\n",
    "    statements_user_count = len(filtered_data_user['statement_ID'].unique())\n",
    "    objects_user_count = len(filtered_data_user['obj_def_name_en'].unique())\n",
    "\n",
    "    # Group data by date and verb to get the count of each verb for each date\n",
    "    verb_counts = filtered_data_user.groupby(['date', 'verb_display_en']).size().reset_index(name='count')\n",
    "\n",
    "    # threshold for calculating time spent based on the statements\n",
    "    threshold_minutes=30\n",
    "\n",
    "    # Calculate time difference between consecutive rows\n",
    "    filtered_data_user['time_diff'] = filtered_data_user['timestamp'].diff()\n",
    "    \n",
    "    # Identify where a new session starts (where time_diff is NaN or greater than threshold)\n",
    "    filtered_data_user['new_session'] = (filtered_data_user['time_diff'].isnull()) | (filtered_data_user['time_diff'] > pd.Timedelta(minutes=threshold_minutes))\n",
    "    \n",
    "    # Assign session numbers\n",
    "    filtered_data_user['session_id'] = filtered_data_user['new_session'].cumsum()\n",
    "    \n",
    "    # Group by day, platform, and session ID to calculate the duration of each session\n",
    "    sessions = filtered_data_user.groupby([filtered_data_user['timestamp'].dt.date, 'platform', 'session_id']).agg(start_time=('timestamp', 'min'), end_time=('timestamp', 'max'))\n",
    "    sessions['duration_minutes'] = (sessions['end_time'] - sessions['start_time']).dt.total_seconds() / 60\n",
    "    \n",
    "    # Drop unnecessary columns\n",
    "    sessions = sessions.drop(columns=['start_time', 'end_time'])\n",
    "    \n",
    "    # Reset index for better structure\n",
    "    sessions_reset = sessions.reset_index()\n",
    "\n",
    "    # Filter data based on selected email and group by object name\n",
    "    user_grouped_data = filtered_data_user[filtered_data_user['actor_mbox'].isin(selected_user)].groupby('obj_def_name_en')\n",
    "\n",
    "    # Calculate the number of statements per object and identify the platform for each group\n",
    "    user_table_data = user_grouped_data.agg(\n",
    "        num_statements=pd.NamedAgg(column='statement_ID', aggfunc='size'),\n",
    "        platform=pd.NamedAgg(column='platform', aggfunc='first')\n",
    "    ).reset_index()\n",
    "    \n",
    "    # Graphs per Platform\n",
    "    distribution_of_verbs_user_fig = px.bar(filtered_data_user, x=filtered_data_user['verb_display_en'].value_counts().index,\n",
    "                      y=filtered_data_user['verb_display_en'].value_counts().values,\n",
    "                      labels={'x': 'Verb', 'y': 'Count'},\n",
    "                      title='Distribution of Verbs')\n",
    "\n",
    "    # Daily statements per day\n",
    "    daily_counts = filtered_data_user.groupby('date').size().reset_index(name='count')\n",
    "\n",
    "    statements_per_day_user_fig = go.Figure()\n",
    "\n",
    "    statements_per_day_user_fig.add_trace(go.Scatter(x=daily_counts['date'], y=daily_counts['count'], mode='lines+markers', name='Time Series',\n",
    "                             line=dict(dash='dashdot')))\n",
    "    \n",
    "    statements_per_day_user_fig.update_layout(title='Statements per Day',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Count')\n",
    "    # Update the layout to add the range slider\n",
    "    statements_per_day_user_fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "  \n",
    "    distribution_per_activity_user_fig = px.pie(filtered_data_user , names='obj_type', title='Distribution per Activity')\n",
    "    languages_user_fig = px.pie(filtered_data_user , names='language', title='Language Distribution')\n",
    "    statements_per_timeframe_user_fig = px.pie(filtered_data_user , names='timeframe', title='Statements per Timeframe')\n",
    "    statements_per_platform_user_fig = px.pie(filtered_data_user , names='platform', title='Statements per Platform')\n",
    "\n",
    "    stat_card_instances_user = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Instances Registered\", className=\"card-title\"),\n",
    "            html.H2(str(instances_user_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"info\", inverse=True)\n",
    "\n",
    "    stat_card_statements_user = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Statements\", className=\"card-title\"),\n",
    "            html.H2(str(statements_user_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"warning\", inverse=True)\n",
    "\n",
    "    stat_card_objects_user = dbc.Card([\n",
    "        dbc.CardBody([\n",
    "            html.H4(\"Total Objects\", className=\"card-title\"),\n",
    "            html.H2(str(objects_user_count), className=\"card-subtitle\"),\n",
    "        ])\n",
    "    ], color=\"danger\", inverse=True)\n",
    "\n",
    "    # Create an interactive table to display the results\n",
    "    user_data_table = dash_table.DataTable(\n",
    "        columns=[\n",
    "            {\"name\": \"Object Name\", \"id\": \"obj_def_name_en\"},\n",
    "            {\"name\": \"Number of Statements\", \"id\": \"num_statements\"},\n",
    "            {\"name\": \"Platform\", \"id\": \"platform\"},\n",
    "        ],\n",
    "        data=user_table_data.to_dict('records'),\n",
    "        filter_action=\"native\",\n",
    "        sort_action=\"native\",\n",
    "        page_action=\"native\",\n",
    "        page_size=10,\n",
    "        style_table={'overflowX': 'auto'},\n",
    "        style_cell={\n",
    "            'textAlign': 'center',\n",
    "            'whiteSpace': 'normal',\n",
    "            'height': 'auto',\n",
    "        },\n",
    "        style_data_conditional=[\n",
    "            {\n",
    "                'if': {'row_index': 'odd'},\n",
    "                'backgroundColor': 'rgb(248, 248, 248)'\n",
    "            }\n",
    "        ],\n",
    "        export_format=\"csv\",\n",
    "        export_headers=\"display\",\n",
    "    )\n",
    "\n",
    "    # Summarize data to get total time spent per day per platform\n",
    "    daily_time_spent = sessions_reset.groupby(['timestamp', 'platform'])['duration_minutes'].sum().reset_index()\n",
    "        \n",
    "    # Create the figure\n",
    "    time_spent_user_fig = go.Figure()\n",
    "        \n",
    "    # For each platform, add a trace to the figure\n",
    "    for platform in daily_time_spent['platform'].unique():\n",
    "        platform_data = daily_time_spent[daily_time_spent['platform'] == platform]\n",
    "        time_spent_user_fig.add_trace(go.Scatter(x=platform_data['timestamp'], y=platform_data['duration_minutes'], \n",
    "                                    mode='lines+markers', name=platform,\n",
    "                                    line=dict(dash='dashdot')))\n",
    "        \n",
    "    # Update the layout\n",
    "    time_spent_user_fig.update_layout(title='Time Spent per Day per Platform (based on xAPI statements with 30 minutes interval)',\n",
    "                          xaxis_title='Date',\n",
    "                          yaxis_title='Minutes Spent')\n",
    "        \n",
    "    # Add the range slider to the x-axis\n",
    "    time_spent_user_fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Create the figure\n",
    "    verbs_over_time_user_fig = go.Figure()\n",
    "    \n",
    "    # For each verb, add a trace to the figure\n",
    "    for verb in verb_counts['verb_display_en'].unique():\n",
    "        verb_data = verb_counts[verb_counts['verb_display_en'] == verb]\n",
    "        verbs_over_time_user_fig.add_trace(go.Scatter(x=verb_data['date'], y=verb_data['count'], \n",
    "                                 mode='lines+markers', name=verb,\n",
    "                                 line=dict(dash='dashdot')))\n",
    "    \n",
    "    # Update the layout\n",
    "    verbs_over_time_user_fig.update_layout(title='Verb Counts Over Time',\n",
    "                      xaxis_title='Date',\n",
    "                      yaxis_title='Count of Verbs')\n",
    "    \n",
    "    # Add the range slider to the x-axis\n",
    "    verbs_over_time_user_fig.update_layout(\n",
    "        xaxis=dict(\n",
    "            rangeslider=dict(\n",
    "                visible=True\n",
    "            ),\n",
    "            type=\"date\"\n",
    "        )\n",
    "    )\n",
    "\n",
    "    return distribution_of_verbs_user_fig, statements_per_day_user_fig, verbs_over_time_user_fig, time_spent_user_fig, distribution_per_activity_user_fig, languages_user_fig, statements_per_timeframe_user_fig, statements_per_platform_user_fig, stat_card_instances_user, stat_card_statements_user, stat_card_objects_user, user_data_table\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    app.run_server(port=8050, debug=True, use_reloader=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9af25f0-c20e-48bb-ad29-c5cb45a72b44",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
